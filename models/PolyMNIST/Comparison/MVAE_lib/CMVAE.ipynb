{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47a73116",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"In this file, we reproduce the results of the CMVAE model on the PolyMNIST dataset.\"\"\"\n",
    "\n",
    "from CMVAE_architectures import Dec, Enc, load_mmnist_classifiers\n",
    "import torch\n",
    "\n",
    "from multivae.data.datasets.mmnist import MMNISTDataset\n",
    "from multivae.models.cmvae import CMVAE, CMVAEConfig\n",
    "from multivae.trainers.base import BaseTrainer, BaseTrainerConfig\n",
    "from multivae.trainers.base.callbacks import ProgressBarCallback, WandbCallback\n",
    "from pythae.data.datasets import DatasetOutput\n",
    "\n",
    "###### Set the paths for loading and saving ######\n",
    "DATA_PATH = \"/home/bigdata/siyi/data\"\n",
    "SAVE_PATH = \"/home/siyi/project/mm/result/runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5824feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Set the paths for loading and saving ######\n",
    "DATA_PATH = \"/home/asenella/data\"\n",
    "SAVE_PATH = \"/home/asenella/experiments\"\n",
    "\n",
    "###### Define model configuration ########\n",
    "modalities = [\"m0\", \"m1\", \"m2\", \"m3\", \"m4\"]\n",
    "\n",
    "model_config = CMVAEConfig(\n",
    "    n_modalities=5,\n",
    "    K=1,\n",
    "    decoders_dist={m: \"laplace\" for m in modalities},\n",
    "    decoder_dist_params={m: dict(scale=0.75) for m in modalities},\n",
    "    prior_and_posterior_dist=\"laplace_with_softmax\",\n",
    "    beta=2.5,\n",
    "    modalities_specific_dim=32,\n",
    "    latent_dim=32,\n",
    "    input_dims={m: (3, 28, 28) for m in modalities},\n",
    "    learn_modality_prior=True,\n",
    "    number_of_clusters=40,\n",
    "    loss=\"iwae_looser\",\n",
    ")\n",
    "\n",
    "encoders = {\n",
    "    m: Enc(model_config.modalities_specific_dim, ndim_u=model_config.latent_dim)\n",
    "    for m in modalities\n",
    "}\n",
    "decoders = {\n",
    "    m: Dec(model_config.latent_dim + model_config.modalities_specific_dim)\n",
    "    for m in modalities\n",
    "}\n",
    "\n",
    "model = CMVAE(model_config, encoders, decoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d65b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MMNISTDataset('/bigdata/siyi/data', modalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76025570",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"/home/siyi/project/mm/result/Dynamic_project/PM51/reproduce_cmvae/K__1/CMVAE_training_2025-09-01_16-26-14/final_model/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f75ccc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f17fbc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_mods = {'m1': train_data[0]['data']['m1'].unsqueeze(0), 'm2': train_data[0]['data']['m2'].unsqueeze(0)}\n",
    "cond_mods_name = ['m1', 'm2']\n",
    "gen_mods_name = ['m0', 'm3', 'm4']\n",
    "out = model.encode(inputs=DatasetOutput(data=cond_mods), cond_mod=cond_mods_name, gen_mod=gen_mods_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c64ebcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelOutput([('z',\n",
       "              tensor([[-1.3466, -4.7154,  0.1109,  0.6420, -0.0188, -3.4930, -1.4929,  0.7362,\n",
       "                        2.2687, -1.4370, -1.5727, -1.4706, -0.7566, -4.5920,  1.8497, -1.8275,\n",
       "                        2.0954,  2.2184,  4.6179,  0.4313,  4.8770,  3.3431,  0.9605, -0.9490,\n",
       "                        0.5719, -1.7380,  0.8560, -6.7802,  0.1557, -2.8408, -0.0209,  0.7917]],\n",
       "                     grad_fn=<SubBackward0>)),\n",
       "             ('one_latent_space', False),\n",
       "             ('modalities_z',\n",
       "              {'m0': tensor([[ 1.2942e-01, -6.9427e-01, -1.3979e+00,  2.6601e-01, -4.2426e+00,\n",
       "                         1.1081e-01,  7.0461e-01, -1.4765e+00,  1.4961e+00, -6.1687e-01,\n",
       "                        -6.1294e-01, -9.0049e-01, -8.0148e-02, -2.9790e-01, -2.8714e-01,\n",
       "                        -1.1054e-01,  1.5925e-01, -6.0271e+00,  5.9336e-01, -6.3538e-01,\n",
       "                         1.7974e-03,  3.9869e+00, -1.2088e-01,  1.7324e+00, -9.1827e-01,\n",
       "                        -7.1025e-01,  8.4242e-01,  3.1876e-01,  7.2353e-01, -7.1261e-01,\n",
       "                         1.5776e+00,  1.8418e+00]], grad_fn=<SubBackward0>),\n",
       "               'm1': tensor([[ 0.3221,  1.8909,  0.2809, -0.8071, -0.8905, -0.2132,  2.6387,  0.5522,\n",
       "                        -0.9395,  0.0696, -0.8023,  0.2693, -0.0499,  2.0748,  4.6202, -4.5058,\n",
       "                         1.7539, -0.4133,  1.4304, -4.4722, -0.1303,  0.0185, -1.4007,  1.6690,\n",
       "                        -2.1846, -2.3799, -0.9234,  0.9462, -0.4123,  0.3022, -1.4513,  0.1952]],\n",
       "                      grad_fn=<SubBackward0>),\n",
       "               'm2': tensor([[-1.9628, -0.4579,  0.0059,  0.7109,  1.6999, -1.3131, -0.7894,  0.4739,\n",
       "                        -4.3178, -1.4542,  2.0407,  0.8440,  0.1813, -1.2008,  0.4938, -0.6054,\n",
       "                        -1.7738, -1.1286,  1.7384,  0.6499, -0.7289, -0.8366, -0.1416,  0.3489,\n",
       "                        -0.9671,  2.2840, -1.5893,  1.5423,  2.7721, -1.1075,  1.4367,  0.9167]]),\n",
       "               'm3': tensor([[ 0.6710,  0.9058,  0.8711, -0.2795,  0.4255,  1.9928,  0.2179, -0.1835,\n",
       "                        -1.0460,  0.4056, -0.1884,  0.5137, -0.4760, -0.6170, -0.6944,  1.0666,\n",
       "                         0.1497,  1.2782,  0.4162,  0.1694,  1.8937, -0.2764, -0.2127, -0.6954,\n",
       "                         1.8364, -0.1597, -1.7009, -0.1565,  0.0219,  1.0943, -0.1144, -1.6634]]),\n",
       "               'm4': tensor([[-2.2797, -0.3534, -0.9846, -0.6349, -0.0377,  0.2874,  0.0580, -0.6022,\n",
       "                         4.0351, -0.7813, -0.5682,  0.7302,  0.3066, -0.3554, -3.6586, -1.5890,\n",
       "                        -1.3694, -0.3282,  0.0710, -0.0509,  0.6221, -0.1155,  0.3103,  0.0636,\n",
       "                         1.2347, -1.1567,  2.4840, -0.9832, -4.3864, -3.4299, -1.0078,  2.2904]])})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfsuper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
