{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1c67368",
   "metadata": {},
   "source": [
    "# Calculate gaussian std and prototypes using consine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "887d1910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siyi/miniconda3/envs/dymo/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import h5py\n",
    "from os.path import join\n",
    "import json\n",
    "current_path = os.getcwd()\n",
    "sys.path.append(os.path.dirname(current_path))\n",
    "\n",
    "from os.path import join\n",
    "from omegaconf import DictConfig, open_dict, OmegaConf\n",
    "from utils.utils import grab_arg_from_checkpoint, prepend_paths, re_prepend_paths, get_transforms\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "plt.rc('font', family='Calibri', size=18)\n",
    "# matplotlib.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rc('legend', loc='best', frameon=True, edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01dd7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "result_folder = '/home/siyi/project/mm/result/Dynamic_project/PM16/demo_DynamicTransformer_singleCLS_singleCLS_whole_none_PolyMNIST_DynamicTransformer_singleCLS_0426_151226'\n",
    "if 'CAD' in result_folder or 'Infarction' in result_folder or 'CelebA' in result_folder:\n",
    "    eval_metric = 'auc'\n",
    "else:\n",
    "    eval_metric = 'acc'\n",
    "checkpoint_path = join(result_folder, f'downstream/checkpoint_best_{eval_metric}.ckpt')\n",
    "ckpt = torch.load(checkpoint_path, map_location='cpu')\n",
    "args = ckpt['hyper_parameters']\n",
    "args = OmegaConf.create(args)\n",
    "args['data_base'] = args.data_base_cq\n",
    "OmegaConf.set_struct(args, False)\n",
    "args.checkpoint = checkpoint_path\n",
    "args.data_base = join(args.data_base, args.data_base_postfix)\n",
    "args = re_prepend_paths(args)\n",
    "hparams = args\n",
    "if 'low' not in args.keys():\n",
    "    args.low = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae031f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PlyMNIST transforms for train mode\n",
      "Missing mask data loaded from /bigdata/siyi/data/MoPoE/PolyMNIST/missing_modality/missing_train_whole_none.csv\n",
      "Missing mask example: [False False False False False]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "if args.dataset_name == 'PolyMNIST':\n",
    "    from datasets.PolyMNISTDataset import PolyMNISTDataset\n",
    "    image_size = grab_arg_from_checkpoint(hparams, 'image_size')\n",
    "    missing_train = 'missing_train_whole_none'\n",
    "    train_dataset = PolyMNISTDataset(\n",
    "        unimodal_datapaths=hparams.DATA_train, data_base=hparams.data_base, missing_path=missing_train, transform=get_transforms(image_size,hparams.target,'train'),\n",
    "        target_transform=None, low=hparams.low)\n",
    "elif args.dataset_name == 'MST':\n",
    "        from datasets.MSTDataset import SVHNMNIST\n",
    "        missing_train = 'none'\n",
    "        flags = {'dir_data': hparams.data_base, 'len_sequence': 8, 'data_multiplications': 20}\n",
    "        flags = OmegaConf.create(flags)\n",
    "        alphabet_path = join(hparams.data_base, 'alphabet.json')\n",
    "        with open(alphabet_path) as alphabet_file:\n",
    "            alphabet = str(''.join(json.load(alphabet_file)))\n",
    "        train_dataset = SVHNMNIST(flags, alphabet, train='train', missing_path=missing_train, transform=get_transforms(hparams.image_size, hparams.target, 'train'))\n",
    "        hparams.alphabet = alphabet\n",
    "elif hparams.dataset_name == 'CelebA':\n",
    "    from datasets.CelebADataset import CelebaDataset\n",
    "    missing_train = 'none'\n",
    "    flags = {'dir_data': hparams.data_base, 'dir_text': hparams.data_base, 'len_sequence': 256, 'random_text_ordering': False, 'random_text_startindex': True}\n",
    "    flags = OmegaConf.create(flags)\n",
    "    alphabet_path = join(hparams.data_base, 'alphabet.json')\n",
    "    with open(alphabet_path) as alphabet_file:\n",
    "        alphabet = str(''.join(json.load(alphabet_file)))\n",
    "    train_dataset = CelebaDataset(flags, alphabet, missing_path=missing_train, partition=0, transform=get_transforms(hparams.image_size, hparams.target, 'train'))\n",
    "    hparams.alphabet = alphabet\n",
    "elif hparams.dataset_name in set(['DVM', 'CAD', 'Infarction']):\n",
    "    from datasets.TIPDataset import ImagingAndTabularDataset\n",
    "    missing_train = 'none'\n",
    "    train_dataset = ImagingAndTabularDataset(\n",
    "                hparams.DATA_data_train_eval_imaging, hparams.delete_segmentation, hparams.augmentation_rate, \n",
    "                hparams.DATA_data_train_eval_tabular, hparams.DATA_field_lengths_tabular, hparams.eval_one_hot,\n",
    "                hparams.DATA_labels_train_eval_imaging, hparams.image_size, hparams.live_loading, train=False, target=hparams.target,\n",
    "                corruption_rate=hparams.corruption_rate, data_base=hparams.data_base, augmentation_speedup=hparams.augmentation_speedup,\n",
    "                missing_tabular=hparams.missing_tabular, missing_strategy=hparams.missing_strategy, missing_rate=hparams.missing_rate,algorithm_name=hparams.algorithm_name,\n",
    "                missing_path=missing_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ceef75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamicTransformer\n",
      "Randomly drop 0 modalities\n",
      "Use distance metric for DynamicTransformer: cosine_similarity\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DynamicTransformer(\n",
       "  (m_encoders): ModuleList(\n",
       "    (0): UnimodalEncoder(\n",
       "      (network): Sequential(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (proj_conv): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (1): UnimodalEncoder(\n",
       "      (network): Sequential(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (proj_conv): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (2): UnimodalEncoder(\n",
       "      (network): Sequential(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (proj_conv): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (3): UnimodalEncoder(\n",
       "      (network): Sequential(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (proj_conv): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (4): UnimodalEncoder(\n",
       "      (network): Sequential(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (proj_conv): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (m_norms): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (modality_embeddings): Embedding(5, 128)\n",
       "  (classifier): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (projection): Linear(in_features=128, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if args.dataset_name == 'PolyMNIST':\n",
    "    from models.PolyMNIST.Dynamic.DynamicTransformer import DynamicTransformer\n",
    "    model = DynamicTransformer(args)\n",
    "elif args.dataset_name == 'MST':\n",
    "    from models.MST.Dynamic.DynamicTransformer import DynamicTransformer\n",
    "    model = DynamicTransformer(args)\n",
    "elif args.dataset_name == 'CelebA':\n",
    "    from models.CelebA.Dynamic.DynamicTransformer import DynamicTransformer\n",
    "    model = DynamicTransformer(args)\n",
    "elif hparams.dataset_name in set(['DVM', 'CAD', 'Infarction']):\n",
    "    from models.TIPData.Dynamic.DynamicTransformer import DynamicTransformer\n",
    "    model = DynamicTransformer(args)\n",
    "model.load_state_dict(ckpt['state_dict'], strict=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4981878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "# folder to store features for each subset\n",
    "storage_folder = result_folder+'/gaussian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2942fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(train_loader, model, mask0):\n",
    "    feat_list = []\n",
    "    y_list = []\n",
    "    y_hat_list = []\n",
    "    for batch in tqdm(train_loader):\n",
    "        x, _, y = batch\n",
    "        for key in x:\n",
    "            x[key] = x[key].to(device)\n",
    "        # y = y.to(device)\n",
    "        mask0 = torch.tensor(mask0).to(device)\n",
    "        mask = mask0.expand(len(y), -1)\n",
    "        # print(mask)\n",
    "        with torch.no_grad():\n",
    "            y_hat, feat = model.forward_train(x, mask)\n",
    "        feat_list.append(feat.cpu().numpy())\n",
    "        y_list.extend(y.cpu().numpy())\n",
    "        y_hat_list.extend(y_hat.cpu().numpy())\n",
    "        # break\n",
    "    feat = np.concatenate(feat_list, axis=0)\n",
    "    y_list = np.array(y_list)\n",
    "    y_hat_list = np.array(y_hat_list)\n",
    "    return feat, y_list, y_hat_list\n",
    "\n",
    "def calculate_class_prototypes(feat, y, num_classes):\n",
    "    feat = np.array(feat)\n",
    "    y = np.array(y)\n",
    "    prototypes = np.zeros((num_classes, feat.shape[1]))\n",
    "    prot_dist_std = np.zeros((num_classes))\n",
    "    t_dist_params = np.zeros((num_classes, 3))\n",
    "    for i in range(num_classes):\n",
    "        mask = (y == i)\n",
    "        feat_i = feat[mask]\n",
    "        prototype = np.mean(feat_i, axis=0, keepdims=True)\n",
    "        prototypes[i] = prototype\n",
    "        similarity = np.dot(feat_i, prototype.T)\n",
    "        if np.max(similarity) > 1:\n",
    "            print(f'similarity max: {np.max(similarity)}, min: {np.min(similarity)}')\n",
    "        whole_similarity = np.concatenate((1-similarity, similarity-1), axis=0)\n",
    "        assert whole_similarity[:len(similarity)].sum() + whole_similarity[len(similarity):].sum() == 0\n",
    "        std = np.std(whole_similarity)\n",
    "        prot_dist_std[i] = std\n",
    "        # fit t-distribution\n",
    "        df, loc, scale = stats.t.fit(whole_similarity)\n",
    "        t_dist_params[i] = [df, loc, scale]\n",
    "    return prototypes, prot_dist_std, t_dist_params, whole_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c890e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2subset = model.id2subset\n",
    "prototypes_all = []\n",
    "dist_std_all = []\n",
    "t_dist_params_all = []\n",
    "model = model.to(device)\n",
    "num_classes = hparams.num_classes\n",
    "print('Number of classes:', num_classes)\n",
    "for subset in id2subset.items():\n",
    "    id, mask0 = subset\n",
    "    print(f'Extracting {id}: {mask0} features')\n",
    "    feat, y, y_hat = extract_feature(train_loader, model, mask0)\n",
    "    prototypes, prot_dist_std, t_dist_params, whole_similarity = calculate_class_prototypes(feat, y, num_classes)\n",
    "    print(whole_similarity.max(), whole_similarity.min())\n",
    "    prototypes_all.append(prototypes)\n",
    "    dist_std_all.append(prot_dist_std)\n",
    "    t_dist_params_all.append(t_dist_params)\n",
    "    # break\n",
    "prototypes_all = torch.from_numpy(np.array(prototypes_all))\n",
    "overall_prototypes = prototypes_all.mean(dim=0)\n",
    "dist_std_all = torch.from_numpy(np.array(dist_std_all))\n",
    "t_dist_params_all = torch.from_numpy(np.array(t_dist_params_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07b7d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store prototypes and std\n",
    "if not os.path.exists(storage_folder):\n",
    "    os.makedirs(storage_folder)\n",
    "subset_gaussian = {\n",
    "    'prototypes': prototypes_all.float(),\n",
    "    'overall_prototypes': overall_prototypes.float(),\n",
    "    'dist_std': dist_std_all.float(),\n",
    "    't_dist_params': t_dist_params_all.float(),\n",
    "    'id2subset': id2subset,\n",
    "    'subset2id': model.subset2id,\n",
    "}\n",
    "torch.save(subset_gaussian, os.path.join(storage_folder, 'subset_gaussian.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fabf0ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole_similarity [[ 0.26287752]\n",
      " [ 0.34177506]\n",
      " [ 0.6449405 ]\n",
      " ...\n",
      " [-0.53106064]\n",
      " [-0.3899665 ]\n",
      " [-0.2327801 ]]\n",
      "std:  [0.35574988 0.38305342]\n",
      "t_dist_params [[ 5.81130627e+03 -5.59180739e-04  3.55789700e-01]\n",
      " [ 1.50072172e+02 -2.14038438e-04  3.80548242e-01]]\n"
     ]
    }
   ],
   "source": [
    "subset_prototypes, subset_prot_dist_std, t_dist_params, whole_similarity = calculate_class_prototypes(feat, y, num_classes)\n",
    "print('whole_similarity', whole_similarity)\n",
    "print('std: ', subset_prot_dist_std)\n",
    "print('t_dist_params', t_dist_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb6490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the similarity distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(whole_similarity, bins=100, density=True, alpha=0.6, color='g', label='whole similarity')\n",
    "plt.axvline(x=0, color='r', linestyle='--', label='0')\n",
    "plt.title('Similarity Distribution')\n",
    "plt.xlabel('Similarity')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dymo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
