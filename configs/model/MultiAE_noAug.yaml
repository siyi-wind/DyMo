# @package _global_
defaults:
  - _self_

model_name: MultiAE

PolyMNIST:
  max_epochs: 100
  batch_size: 256
  lr_downstream: 0.001
  weight_decay_downstream: 0
  pretrain: False
  downstream_strategy: "frozen"
  checkpoint: /home/siyi/project/mm/result/Dynamic_project/PM31/whole_none_PolyMNIST_MultiAE_0530_162650/pretrain/checkpoint_last_epoch_299.ckpt
  # model specific
  augmentation_K: 
  embedding_size: 512

  max_epochs_pretrain: 300
  lr_pretrain: 0.001
  weight_decay_pretrain: 0


MST:
  max_epochs: 20
  batch_size: 256
  lr_downstream: 0.001
  weight_decay_downstream: 0
  pretrain: False
  downstream_strategy: "frozen"
  checkpoint: /home/siyi/project/mm/result/Dynamic_project/MS12/whole_none_MST_MultiAE_0530_170327/pretrain/checkpoint_last_epoch_199.ckpt
  # model specific
  augmentation_K: 
  embedding_size: 32

  max_epochs_pretrain: 200
  lr_pretrain: 0.001
  weight_decay_pretrain: 0


CelebA:
  max_epochs: 20
  batch_size: 256
  lr_downstream: 0.001
  weight_decay_downstream: 0
  pretrain: False
  downstream_strategy: "frozen"
  checkpoint: /home/siyi/project/mm/result/Dynamic_project/CA12/none_CelebA_MultiAE_0530_170459/pretrain/checkpoint_last_epoch_199.ckpt
  # model specific
  augmentation_K: 
  embedding_size: 32

  max_epochs_pretrain: 200
  lr_pretrain: 0.001
  weight_decay_pretrain: 0


DVM:
  max_epochs: 300
  batch_size: 200
  lr_downstream: 0.0003
  weight_decay_downstream: 0
  pretrain: False
  downstream_strategy: "frozen"
  # model specific
  checkpoint:
  augmentation_K: 
  embedding_size: 256

  max_epochs_pretrain: 300
  lr_pretrain: 0.001
  weight_decay_pretrain: 0